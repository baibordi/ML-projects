{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8ea4c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2351f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Age</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Tax</th>\n",
       "      <th>DisadvantagedPosition</th>\n",
       "      <th>Crime</th>\n",
       "      <th>NitricOxides</th>\n",
       "      <th>PupilTeacher</th>\n",
       "      <th>Residential</th>\n",
       "      <th>NonRetail</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.565</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.0635</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>17.16</td>\n",
       "      <td>8.79212</td>\n",
       "      <td>0.584</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.879</td>\n",
       "      <td>77.7</td>\n",
       "      <td>3.2721</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>9.93</td>\n",
       "      <td>0.62356</td>\n",
       "      <td>0.507</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.972</td>\n",
       "      <td>76.7</td>\n",
       "      <td>3.1025</td>\n",
       "      <td>4</td>\n",
       "      <td>304</td>\n",
       "      <td>9.97</td>\n",
       "      <td>0.34940</td>\n",
       "      <td>0.544</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.943</td>\n",
       "      <td>97.4</td>\n",
       "      <td>1.8773</td>\n",
       "      <td>5</td>\n",
       "      <td>403</td>\n",
       "      <td>4.59</td>\n",
       "      <td>1.22358</td>\n",
       "      <td>0.605</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>41.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.926</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.9084</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>18.13</td>\n",
       "      <td>15.57570</td>\n",
       "      <td>0.580</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>6.019</td>\n",
       "      <td>65.3</td>\n",
       "      <td>2.4091</td>\n",
       "      <td>6</td>\n",
       "      <td>391</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.23912</td>\n",
       "      <td>0.585</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>5.936</td>\n",
       "      <td>80.3</td>\n",
       "      <td>2.7792</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>16.94</td>\n",
       "      <td>8.20058</td>\n",
       "      <td>0.713</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>6.590</td>\n",
       "      <td>40.4</td>\n",
       "      <td>5.4917</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.03537</td>\n",
       "      <td>0.433</td>\n",
       "      <td>16.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.09</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>6.405</td>\n",
       "      <td>85.4</td>\n",
       "      <td>2.7147</td>\n",
       "      <td>5</td>\n",
       "      <td>384</td>\n",
       "      <td>10.63</td>\n",
       "      <td>0.22876</td>\n",
       "      <td>0.520</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>6.556</td>\n",
       "      <td>29.1</td>\n",
       "      <td>4.5667</td>\n",
       "      <td>5</td>\n",
       "      <td>398</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.12579</td>\n",
       "      <td>0.437</td>\n",
       "      <td>15.2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rooms   Age  Distance  Accessibility  Tax  DisadvantagedPosition  \\\n",
       "0    5.565  70.6    2.0635             24  666                  17.16   \n",
       "1    6.879  77.7    3.2721              8  307                   9.93   \n",
       "2    5.972  76.7    3.1025              4  304                   9.97   \n",
       "3    6.943  97.4    1.8773              5  403                   4.59   \n",
       "4    5.926  71.0    2.9084             24  666                  18.13   \n",
       "..     ...   ...       ...            ...  ...                    ...   \n",
       "394  6.019  65.3    2.4091              6  391                  12.92   \n",
       "395  5.936  80.3    2.7792             24  666                  16.94   \n",
       "396  6.590  40.4    5.4917              7  329                   9.50   \n",
       "397  6.405  85.4    2.7147              5  384                  10.63   \n",
       "398  6.556  29.1    4.5667              5  398                   4.56   \n",
       "\n",
       "        Crime  NitricOxides  PupilTeacher  Residential  NonRetail  Price  \n",
       "0     8.79212         0.584          20.2          0.0      18.10   11.7  \n",
       "1     0.62356         0.507          17.4          0.0       6.20   27.5  \n",
       "2     0.34940         0.544          18.4          0.0       9.90   20.3  \n",
       "3     1.22358         0.605          14.7          0.0      19.58   41.3  \n",
       "4    15.57570         0.580          20.2          0.0      18.10   19.1  \n",
       "..        ...           ...           ...          ...        ...    ...  \n",
       "394   0.23912         0.585          19.2          0.0       9.69   21.2  \n",
       "395   8.20058         0.713          20.2          0.0      18.10   13.5  \n",
       "396   0.03537         0.433          16.1         34.0       6.09   22.0  \n",
       "397   0.22876         0.520          20.9          0.0       8.56   18.6  \n",
       "398   0.12579         0.437          15.2         45.0       3.44   29.8  \n",
       "\n",
       "[399 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Kyle\\Desktop\\Middlesex uni\\Machine Learning\\Week8\\house_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a125cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 399 entries, 0 to 398\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Rooms                  399 non-null    float64\n",
      " 1   Age                    399 non-null    float64\n",
      " 2   Distance               399 non-null    float64\n",
      " 3   Accessibility          399 non-null    int64  \n",
      " 4   Tax                    399 non-null    int64  \n",
      " 5   DisadvantagedPosition  399 non-null    float64\n",
      " 6   Crime                  399 non-null    float64\n",
      " 7   NitricOxides           399 non-null    float64\n",
      " 8   PupilTeacher           399 non-null    float64\n",
      " 9   Residential            399 non-null    float64\n",
      " 10  NonRetail              399 non-null    float64\n",
      " 11  Price                  399 non-null    float64\n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 37.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5903c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Age</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Tax</th>\n",
       "      <th>DisadvantagedPosition</th>\n",
       "      <th>Crime</th>\n",
       "      <th>NitricOxides</th>\n",
       "      <th>PupilTeacher</th>\n",
       "      <th>Residential</th>\n",
       "      <th>NonRetail</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.313130</td>\n",
       "      <td>68.776441</td>\n",
       "      <td>3.765977</td>\n",
       "      <td>9.609023</td>\n",
       "      <td>410.451128</td>\n",
       "      <td>12.489975</td>\n",
       "      <td>3.975191</td>\n",
       "      <td>0.555370</td>\n",
       "      <td>18.483960</td>\n",
       "      <td>11.966165</td>\n",
       "      <td>11.104010</td>\n",
       "      <td>22.703509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.709658</td>\n",
       "      <td>28.483255</td>\n",
       "      <td>2.149947</td>\n",
       "      <td>8.782264</td>\n",
       "      <td>170.424454</td>\n",
       "      <td>7.143052</td>\n",
       "      <td>9.431691</td>\n",
       "      <td>0.116655</td>\n",
       "      <td>2.178329</td>\n",
       "      <td>24.231416</td>\n",
       "      <td>6.996832</td>\n",
       "      <td>9.682972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.888500</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>2.058100</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>0.078805</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>16.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.240000</td>\n",
       "      <td>77.700000</td>\n",
       "      <td>3.102500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>10.880000</td>\n",
       "      <td>0.253560</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>21.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.642000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>5.116700</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>16.950000</td>\n",
       "      <td>3.805910</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>26.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rooms         Age    Distance  Accessibility         Tax  \\\n",
       "count  399.000000  399.000000  399.000000     399.000000  399.000000   \n",
       "mean     6.313130   68.776441    3.765977       9.609023  410.451128   \n",
       "std      0.709658   28.483255    2.149947       8.782264  170.424454   \n",
       "min      3.561000    2.900000    1.129600       1.000000  187.000000   \n",
       "25%      5.888500   45.500000    2.058100       4.000000  277.000000   \n",
       "50%      6.240000   77.700000    3.102500       5.000000  334.000000   \n",
       "75%      6.642000   94.500000    5.116700      24.000000  666.000000   \n",
       "max      8.780000  100.000000   12.126500      24.000000  711.000000   \n",
       "\n",
       "       DisadvantagedPosition       Crime  NitricOxides  PupilTeacher  \\\n",
       "count             399.000000  399.000000    399.000000    399.000000   \n",
       "mean               12.489975    3.975191      0.555370     18.483960   \n",
       "std                 7.143052    9.431691      0.116655      2.178329   \n",
       "min                 1.730000    0.006320      0.385000     12.600000   \n",
       "25%                 6.825000    0.078805      0.449000     17.400000   \n",
       "50%                10.880000    0.253560      0.538000     19.100000   \n",
       "75%                16.950000    3.805910      0.631000     20.200000   \n",
       "max                37.970000   88.976200      0.871000     22.000000   \n",
       "\n",
       "       Residential   NonRetail       Price  \n",
       "count   399.000000  399.000000  399.000000  \n",
       "mean     11.966165   11.104010   22.703509  \n",
       "std      24.231416    6.996832    9.682972  \n",
       "min       0.000000    0.740000    5.000000  \n",
       "25%       0.000000    4.950000   16.550000  \n",
       "50%       0.000000    8.560000   21.400000  \n",
       "75%      17.750000   18.100000   26.450000  \n",
       "max     100.000000   27.740000   50.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b130cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df, kind='scatter', plot_kws={'alpha':0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01152b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Age</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Tax</th>\n",
       "      <th>DisadvantagedPosition</th>\n",
       "      <th>Crime</th>\n",
       "      <th>NitricOxides</th>\n",
       "      <th>PupilTeacher</th>\n",
       "      <th>Residential</th>\n",
       "      <th>NonRetail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.565</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.0635</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>17.16</td>\n",
       "      <td>8.79212</td>\n",
       "      <td>0.584</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.879</td>\n",
       "      <td>77.7</td>\n",
       "      <td>3.2721</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>9.93</td>\n",
       "      <td>0.62356</td>\n",
       "      <td>0.507</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.972</td>\n",
       "      <td>76.7</td>\n",
       "      <td>3.1025</td>\n",
       "      <td>4</td>\n",
       "      <td>304</td>\n",
       "      <td>9.97</td>\n",
       "      <td>0.34940</td>\n",
       "      <td>0.544</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.943</td>\n",
       "      <td>97.4</td>\n",
       "      <td>1.8773</td>\n",
       "      <td>5</td>\n",
       "      <td>403</td>\n",
       "      <td>4.59</td>\n",
       "      <td>1.22358</td>\n",
       "      <td>0.605</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.926</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.9084</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>18.13</td>\n",
       "      <td>15.57570</td>\n",
       "      <td>0.580</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>6.019</td>\n",
       "      <td>65.3</td>\n",
       "      <td>2.4091</td>\n",
       "      <td>6</td>\n",
       "      <td>391</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.23912</td>\n",
       "      <td>0.585</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>5.936</td>\n",
       "      <td>80.3</td>\n",
       "      <td>2.7792</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>16.94</td>\n",
       "      <td>8.20058</td>\n",
       "      <td>0.713</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>6.590</td>\n",
       "      <td>40.4</td>\n",
       "      <td>5.4917</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.03537</td>\n",
       "      <td>0.433</td>\n",
       "      <td>16.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>6.405</td>\n",
       "      <td>85.4</td>\n",
       "      <td>2.7147</td>\n",
       "      <td>5</td>\n",
       "      <td>384</td>\n",
       "      <td>10.63</td>\n",
       "      <td>0.22876</td>\n",
       "      <td>0.520</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>6.556</td>\n",
       "      <td>29.1</td>\n",
       "      <td>4.5667</td>\n",
       "      <td>5</td>\n",
       "      <td>398</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.12579</td>\n",
       "      <td>0.437</td>\n",
       "      <td>15.2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rooms   Age  Distance  Accessibility  Tax  DisadvantagedPosition  \\\n",
       "0    5.565  70.6    2.0635             24  666                  17.16   \n",
       "1    6.879  77.7    3.2721              8  307                   9.93   \n",
       "2    5.972  76.7    3.1025              4  304                   9.97   \n",
       "3    6.943  97.4    1.8773              5  403                   4.59   \n",
       "4    5.926  71.0    2.9084             24  666                  18.13   \n",
       "..     ...   ...       ...            ...  ...                    ...   \n",
       "394  6.019  65.3    2.4091              6  391                  12.92   \n",
       "395  5.936  80.3    2.7792             24  666                  16.94   \n",
       "396  6.590  40.4    5.4917              7  329                   9.50   \n",
       "397  6.405  85.4    2.7147              5  384                  10.63   \n",
       "398  6.556  29.1    4.5667              5  398                   4.56   \n",
       "\n",
       "        Crime  NitricOxides  PupilTeacher  Residential  NonRetail  \n",
       "0     8.79212         0.584          20.2          0.0      18.10  \n",
       "1     0.62356         0.507          17.4          0.0       6.20  \n",
       "2     0.34940         0.544          18.4          0.0       9.90  \n",
       "3     1.22358         0.605          14.7          0.0      19.58  \n",
       "4    15.57570         0.580          20.2          0.0      18.10  \n",
       "..        ...           ...           ...          ...        ...  \n",
       "394   0.23912         0.585          19.2          0.0       9.69  \n",
       "395   8.20058         0.713          20.2          0.0      18.10  \n",
       "396   0.03537         0.433          16.1         34.0       6.09  \n",
       "397   0.22876         0.520          20.9          0.0       8.56  \n",
       "398   0.12579         0.437          15.2         45.0       3.44  \n",
       "\n",
       "[399 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop(['Price'], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a758050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price\n",
       "0     11.7\n",
       "1     27.5\n",
       "2     20.3\n",
       "3     41.3\n",
       "4     19.1\n",
       "..     ...\n",
       "394   21.2\n",
       "395   13.5\n",
       "396   22.0\n",
       "397   18.6\n",
       "398   29.8\n",
       "\n",
       "[399 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=df[['Price']]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94c73667",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest=train_test_split(X,Y, test_size=0.3, random_state=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b6f1ee",
   "metadata": {},
   "source": [
    "# same scaling parameters learned from the training data are applied to both the training and test data consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "231c1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "Xtrain_standard = scaler.fit_transform(Xtrain)\n",
    "\n",
    "# Transform the test data using the fitted scaler from the training data\n",
    "Xtest_standard = scaler.fit_transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3a23dcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.7483537761555816\n",
      "Mean Squared Error: 20.960066772450205\n",
      "Coefficients: [[ 2.25114606  0.87558167 -2.74763462  3.38405472 -2.32656873 -5.4814175\n",
      "  -1.54000622 -1.75647427 -2.30584629  0.81187957  0.40534502]]\n",
      "Intercept: [22.9046595]\n",
      "mean_Ypred: 22.90465949820789\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(Xtrain_standard, Ytrain)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Ypred = model.predict(Xtest_standard)\n",
    "\n",
    "mean_Ypred=np.mean(Ypred)\n",
    "\n",
    "# Calculate R^2 score and Mean Squared Error\n",
    "score = r2_score(Ytest, Ypred)\n",
    "mse = mean_squared_error(Ytest, Ypred)\n",
    "\n",
    "print(\"R^2 Score:\", score)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"mean_Ypred:\", mean_Ypred)\n",
    "#print(\"Predictions:\", Ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91da9b3",
   "metadata": {},
   "source": [
    "# # making predictions that align with the true outcomes. It indicates that the model is performing reasonably well in capturing the relationship between the input features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "47ed80bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x25f064c86d0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Ypred, Ytest, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3091c875",
   "metadata": {},
   "source": [
    "# By implement Ordinary Least Square, the same coefficients and interccept as Linear regression are achieved¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5b4872e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Price   R-squared:                       0.717\n",
      "Model:                            OLS   Adj. R-squared:                  0.706\n",
      "Method:                 Least Squares   F-statistic:                     61.61\n",
      "Date:                Tue, 12 Mar 2024   Prob (F-statistic):           9.58e-67\n",
      "Time:                        00:30:03   Log-Likelihood:                -858.92\n",
      "No. Observations:                 279   AIC:                             1742.\n",
      "Df Residuals:                     267   BIC:                             1785.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         22.9047      0.322     71.189      0.000      22.271      23.538\n",
      "x1             2.2511      0.430      5.236      0.000       1.405       3.098\n",
      "x2             0.8756      0.548      1.597      0.112      -0.204       1.955\n",
      "x3            -2.7476      0.631     -4.356      0.000      -3.990      -1.506\n",
      "x4             3.3841      0.845      4.005      0.000       1.720       5.048\n",
      "x5            -2.3266      0.944     -2.464      0.014      -4.186      -0.467\n",
      "x6            -5.4814      0.533    -10.281      0.000      -6.531      -4.432\n",
      "x7            -1.5400      0.427     -3.604      0.000      -2.381      -0.699\n",
      "x8            -1.7565      0.694     -2.532      0.012      -3.122      -0.391\n",
      "x9            -2.3058      0.418     -5.511      0.000      -3.130      -1.482\n",
      "x10            0.8119      0.463      1.755      0.080      -0.099       1.723\n",
      "x11            0.4053      0.640      0.633      0.527      -0.856       1.666\n",
      "==============================================================================\n",
      "Omnibus:                       78.860   Durbin-Watson:                   2.074\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              200.186\n",
      "Skew:                           1.312   Prob(JB):                     3.39e-44\n",
      "Kurtosis:                       6.215   Cond. No.                         9.28\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "Xnew=sm.add_constant(Xtrain_standard)\n",
    "ols_model=sm.OLS(Ytrain,Xnew)\n",
    "ols_result=ols_model.fit()\n",
    "print(ols_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "de5a1159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Function:\n",
      "Y = 22.90 + 2.25 * X_1 + 0.88 * X_2 + -2.75 * X_3 + 3.38 * X_4 + -2.33 * X_5 + -5.48 * X_6 + -1.54 * X_7 + -1.76 * X_8 + -2.31 * X_9 + 0.81 * X_10 + 0.41 * X_11\n"
     ]
    }
   ],
   "source": [
    "# Get intercept from results\n",
    "const = ols_result.params[0]\n",
    "\n",
    "# Get coefficients (excluding intercept)\n",
    "coefficients = ols_result.params[1:]\n",
    "\n",
    "# Initialize final function string with intercept\n",
    "final_function = f\"Y = {const:.2f}\"\n",
    "\n",
    "# Add terms for each coefficient and corresponding feature\n",
    "for i, coefficient in enumerate(coefficients):\n",
    "    final_function += f\" + {coefficient:.2f} * X_{i+1}\"\n",
    "\n",
    "# Print the final function\n",
    "print(\"Final Function:\")\n",
    "print(final_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64fed8",
   "metadata": {},
   "source": [
    "# implement RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7ef68268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.849686830663793\n",
      "Mean Squared Error: 12.51985433333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([16.836, 35.706, 24.087, 14.057, 23.257, 23.639, 19.835, 19.945,\n",
       "       15.887, 33.415, 19.096, 24.611, 24.848, 26.037, 33.169, 23.791,\n",
       "       15.069, 21.311, 24.884, 20.087, 34.385, 26.219, 34.109, 27.093,\n",
       "       16.812, 45.002, 23.184, 10.928, 14.281, 17.429, 21.599, 19.579,\n",
       "       17.329, 22.316, 11.512, 20.776, 32.59 , 20.291, 16.142, 20.346,\n",
       "       22.753, 22.685, 18.325, 31.774, 19.947, 13.244, 10.916, 21.284,\n",
       "       23.787, 18.773, 23.822, 35.311, 21.815, 10.7  , 14.67 , 19.925,\n",
       "       20.035, 21.184, 20.834, 34.761, 47.833, 23.767, 19.505, 20.987,\n",
       "       16.148, 19.168, 19.137, 17.743, 33.63 ,  8.041, 20.336, 24.018,\n",
       "       18.524, 12.733, 16.475, 21.991, 15.923, 30.553, 33.646, 14.458,\n",
       "       19.823, 18.934,  8.378, 22.301, 20.705, 22.768, 16.286,  8.281,\n",
       "       16.322, 25.056, 21.312, 11.316, 12.844, 14.687, 14.553, 36.242,\n",
       "        8.59 , 28.481, 23.703, 36.865, 21.283, 29.612, 32.69 , 43.491,\n",
       "       22.852, 18.054, 13.127, 14.485, 18.889, 27.597, 49.145, 45.498,\n",
       "       18.789, 13.023, 18.483, 21.74 , 41.611, 19.982, 20.348, 39.816])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest Regressor with default parameters\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_regressor.fit(Xtrain_standard, Ytrain)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rf_regressor.predict(Xtest_standard)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(Ytest, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(Ytest, y_pred)\n",
    "\n",
    "print(\"R^2 Score:\", r2)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c60249",
   "metadata": {},
   "source": [
    "# By implement K-Fold in LinearRegression for cross validation the results of r2_score and mean_squared_error which are the metrics of evaluating the model have better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b6a62262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation R-squared scores: [0.75178037 0.55665508 0.75295693 0.85212307 0.67783226 0.71050876]\n",
      "Mean R-squared score: 0.7169760790989584\n",
      "\n",
      "Cross-validation MSE scores: [-21.52599747 -37.84941727 -15.08514208 -12.289626   -39.31625373\n",
      " -33.90666311]\n",
      "Mean MSE score: -26.662183276194384\n",
      "Bias^2: 69.0445750952745\n",
      "Variance: 69.04454986103549\n"
     ]
    }
   ],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_folds = 6\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X, Y, scoring='r2', cv=kf)\n",
    "\n",
    "# Print the cross-validation scores for R-squared\n",
    "print(\"Cross-validation R-squared scores:\", cv_scores)\n",
    "\n",
    "# Calculate and print the mean R-squared score\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "print(\"Mean R-squared score:\", mean_cv_score)\n",
    "print()\n",
    "\n",
    "# Define a custom scoring function for Mean Squared Error (MSE)\n",
    "def custom_mse_scoring_function(estimator, X, Y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    mse = mean_squared_error(Y, y_pred)\n",
    "    return -mse  # Note: We negate MSE to match the convention of maximizing scores\n",
    "\n",
    "# Perform k-fold cross-validation for MSE\n",
    "cv_scores_mse = cross_val_score(model, X, Y, scoring=custom_mse_scoring_function, cv=kf)\n",
    "\n",
    "# Print the cross-validation MSE scores\n",
    "print(\"Cross-validation MSE scores:\", cv_scores_mse)\n",
    "\n",
    "# Calculate and print the mean MSE score\n",
    "mean_cv_score_mse = np.mean(cv_scores_mse)\n",
    "print(\"Mean MSE score:\", mean_cv_score_mse)\n",
    "\n",
    "# Calculate Bias^2\n",
    "bias_squared = np.mean((y_pred_cv - np.mean(Y))**2)\n",
    "\n",
    "# Calculate Variance\n",
    "variance = np.var(y_pred_cv)\n",
    "\n",
    "# Print Bias^2 and Variance\n",
    "print(\"Bias^2:\", bias_squared)\n",
    "print(\"Variance:\", variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb965db",
   "metadata": {},
   "source": [
    "# compare 2linearregression model:Overall, the second Linear Regression model (with cross-validation) appears to be more reliable as it provides a more generalizable assessment of the model's performance. Despite the slightly lower R^2 score, it has a significantly lower mean squared error, indicating better prediction accuracy on unseen data. Additionally, the cross-validation approach helps in evaluating the model's performance across different subsets of the data, providing more robust insights into its generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320ec80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5f0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dcdc672",
   "metadata": {},
   "source": [
    "# By implement K-Fold in DecisionTreeRegressor for cross validation the results of r2_score and mean_squared_error which are the metrics of evaluating the model have better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a170a05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation R-squared scores: [0.53686576 0.7451936  0.78339892 0.84991075 0.1365146  0.9234268 ]\n",
      "Mean R-squared score: 0.6625517404298152\n",
      "\n",
      "Cross-validation MSE scores: [ 44.27402985  16.73179104  16.42746269  14.16318182 107.01257576\n",
      "   8.57545455]\n",
      "Mean MSE score: 34.53074928388361\n",
      "Bias^2: 69.0445750952745\n",
      "Variance: 69.04454986103549\n"
     ]
    }
   ],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_folds = 6\n",
    "\n",
    "# Create a Decision Tree Regressor model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "cv_scores_r2 = cross_val_score(model, X, Y, scoring='r2', cv=kf)\n",
    "\n",
    "# Print the cross-validation scores for R-squared\n",
    "print(\"Cross-validation R-squared scores:\", cv_scores_r2)\n",
    "\n",
    "# Calculate and print the mean R-squared score\n",
    "mean_cv_score_r2 = np.mean(cv_scores_r2)\n",
    "print(\"Mean R-squared score:\", mean_cv_score_r2)\n",
    "print()\n",
    "\n",
    "# Define a custom scoring function for Mean Squared Error (MSE)\n",
    "def custom_mse_scoring_function(estimator, X, Y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    mse = mean_squared_error(Y, y_pred)\n",
    "    return mse\n",
    "\n",
    "# Perform k-fold cross-validation for MSE\n",
    "cv_scores_mse = cross_val_score(model, X, Y, scoring=custom_mse_scoring_function, cv=kf)\n",
    "\n",
    "# Print the cross-validation MSE scores\n",
    "print(\"Cross-validation MSE scores:\", cv_scores_mse)\n",
    "\n",
    "# Calculate and print the mean MSE score\n",
    "mean_cv_score_mse = np.mean(cv_scores_mse)\n",
    "print(\"Mean MSE score:\", mean_cv_score_mse)\n",
    "\n",
    "# Calculate Bias^2\n",
    "bias_squared = np.mean((y_pred_cv - np.mean(Y))**2)\n",
    "\n",
    "# Calculate Variance\n",
    "variance = np.var(y_pred_cv)\n",
    "\n",
    "# Print Bias^2 and Variance\n",
    "print(\"Bias^2:\", bias_squared)\n",
    "print(\"Variance:\", variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edab8e84",
   "metadata": {},
   "source": [
    "# based on the mse this model can perform better on unseen dataset because of  MSE in comparison with linearregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137f347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6539020c",
   "metadata": {},
   "source": [
    "# By implementing Kfold cross validarion, Having both bias and variance at similar levels can indicate that the model suffers from both underfitting and overfitting simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dbad30",
   "metadata": {},
   "source": [
    "# Implement  GridSearch for improving HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74acad02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=6, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=6, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=6, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': [5, 10, 15]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "param_grid = {\"max_depth\": [5, 10, 15]}\n",
    "gs = GridSearchCV(DecisionTreeRegressor(), param_grid, scoring='neg_mean_squared_error', cv=6)\n",
    "gs.fit(Xtrain_standard, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "de11dabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.7282332526917827\n",
      "Mean Squared Error: 22.63594137471966\n",
      "Bias^2: 79.70318921264695\n",
      "Variance: 79.6733945421283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_estimator = gs.best_estimator_\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "Y_pred = best_estimator.predict(Xtest_standard)\n",
    "\n",
    "# Calculate the R^2 score\n",
    "r2 = r2_score(Ytest, Y_pred)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(Ytest, Y_pred)\n",
    "\n",
    "print(\"R^2 Score:\", r2)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate Bias^2\n",
    "bias_squared = np.mean((Y_pred - np.mean(Ytest))**2)\n",
    "\n",
    "# Calculate Variance\n",
    "variance = np.var(Y_pred)\n",
    "\n",
    "# Print Bias^2 and Variance\n",
    "print(\"Bias^2:\", bias_squared)\n",
    "print(\"Variance:\", variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51231ee9",
   "metadata": {},
   "source": [
    "# Apply polyonomial transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a852cf4",
   "metadata": {},
   "source": [
    "# Degree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a58358e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Intercept: [21.04930251]\n",
      "R^2 Score: -0.7924761391402595\n",
      "Mean Squared Error: 149.29856284126757\n",
      "Bias2: 97.79177040377179\n",
      "Variance2: 90.99546396891893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Degree 2 polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)\n",
    "X_train_poly2 = poly.fit_transform(Xtrain_standard)\n",
    "X_test_poly2 = poly.transform(Xtest_standard)\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly2, Ytrain)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred_poly2 = model.predict(X_test_poly2)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2_score_poly2 = r2_score(Ytest, Y_pred_poly2)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_poly2 = mean_squared_error(Ytest, Y_pred_poly2)\n",
    "\n",
    "#print(\"Model Coefficients:\", model.coef_)\n",
    "print(\"Model Intercept:\", model.intercept_)\n",
    "print(\"R^2 Score:\", r2_score_poly2)\n",
    "print(\"Mean Squared Error:\", mse_poly2)\n",
    "\n",
    "\n",
    "y_train_pred2 = model.predict(X_train_poly2)\n",
    "y_test_pred2 = model.predict(X_test_poly2)\n",
    "\n",
    "# Compute bias and variance\n",
    "bias = np.mean((Ytrain - np.mean(y_train_pred2)) ** 2)\n",
    "variance = np.mean(np.var(y_train_pred2))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Bias2:\", bias)\n",
    "print(\"Variance2:\", variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff9ccd",
   "metadata": {},
   "source": [
    "# Negative R-squared value indicates that the model is not useful for explaining or predicting the variability in the dependent variable, and it suggests that a different model or approach should be considered.\n",
    "the model's performance is poor, and it is unable to explain any of the variance in the target variable. Overall, these results suggest that the model may suffer from overfitting or underfitting and requires further investigation and possibly revision to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f333938",
   "metadata": {},
   "source": [
    "# Implement Ridge for improving Bias and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "473bbf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Intercept: [22.30353709]\n",
      "R^2 Score (Ridge): 0.8285633782019695\n",
      "Mean Squared Error (Ridge): 14.27926469642399\n",
      "Bias (Ridge): 97.85079132276421\n",
      "Variance (Ridge): 80.83030042266155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Degree 2 polynomial features\n",
    "\n",
    "\n",
    "# Initialize Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)  # You can adjust the alpha parameter as needed\n",
    "\n",
    "# Fit the Ridge regression model\n",
    "ridge_model.fit(X_train_poly2, Ytrain)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred_ridge = ridge_model.predict(X_test_poly2)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2_score_ridge = r2_score(Ytest, Y_pred_ridge)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_ridge = mean_squared_error(Ytest, Y_pred_ridge)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Ridge Coefficients:\", ridge_model.coef_)\n",
    "print(\"Ridge Intercept:\", ridge_model.intercept_)\n",
    "print(\"R^2 Score (Ridge):\", r2_score_ridge)\n",
    "print(\"Mean Squared Error (Ridge):\", mse_ridge)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use cross-validation to calculate R^2 scores\n",
    "r2_scores_ridge = cross_val_score(ridge_model, X_train_poly2, Ytrain, cv=5)\n",
    "\n",
    "# Calculate bias and variance\n",
    "bias_ridge = np.mean((Ytrain - np.mean(Y_pred_ridge)) ** 2)\n",
    "variance_ridge = np.mean(np.var(Y_pred_ridge))\n",
    "\n",
    "print(\"Bias (Ridge):\", bias_ridge)\n",
    "print(\"Variance (Ridge):\", variance_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0025f15",
   "metadata": {},
   "source": [
    "# The Ridge regression model outperforms the polynomial regression model in terms of r score and MSE, indicating better predictive performance and lower error.\n",
    "The Ridge regression model has a slightly higher intercept, suggesting a slight shift in the prediction bias.\n",
    "The Ridge regression model exhibits lower variance, indicating more stable predictions across different subsets of the training data.\n",
    "In summary, the results suggest that the Ridge regression model provides a better fit to the data and improves predictive performance compared to the polynomial regression model. The regularization introduced by Ridge regression helps to mitigate overfitting and improve the model's generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c63d3",
   "metadata": {},
   "source": [
    "# Implement Lasso for improving Bias and Variance but Ridge model works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0664dc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Intercept: [21.86151442]\n",
      "R^2 Score (Lasso): 0.793065224413771\n",
      "Mean Squared Error (Lasso): 17.235969797468368\n",
      "Bias (Lasso): 97.79178064655373\n",
      "Variance (Lasso): 60.15469245285103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initialize Lasso regression model\n",
    "lasso_model = Lasso(alpha=1.0)  # You can adjust the alpha parameter as needed\n",
    "\n",
    "# Fit the Lasso regression model\n",
    "lasso_model.fit(X_train_poly2, Ytrain)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred_lasso = lasso_model.predict(X_test_poly2)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2_score_lasso = r2_score(Ytest, Y_pred_lasso)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_lasso = mean_squared_error(Ytest, Y_pred_lasso)\n",
    "\n",
    "#print(\"Lasso Coefficients:\", lasso_model.coef_)\n",
    "print(\"Lasso Intercept:\", lasso_model.intercept_)\n",
    "print(\"R^2 Score (Lasso):\", r2_score_lasso)\n",
    "print(\"Mean Squared Error (Lasso):\", mse_lasso)\n",
    "\n",
    "# Use cross-validation to calculate R^2 scores\n",
    "r2_scores_lasso = cross_val_score(lasso_model, X_train_poly2, Ytrain, cv=5)\n",
    "\n",
    "# Calculate bias and variance\n",
    "bias_lasso = np.mean((Ytrain - np.mean(Y_pred_lasso)) ** 2)\n",
    "variance_lasso = np.mean(np.var(Y_pred_lasso))\n",
    "\n",
    "print(\"Bias (Lasso):\", bias_lasso)\n",
    "print(\"Variance (Lasso):\", variance_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9974624",
   "metadata": {},
   "source": [
    "# Ridge regression has a slightly higher R2_score and lower mean squared error compared to Lasso regression, indicating that Ridge regression might be performing slightly better in terms of predictive accuracy.\n",
    "\n",
    "Bias and Variance Tradeoff: Ridge regression has higher bias but lower variance compared to Lasso regression. This suggests that Ridge regression may provide more stable predictions across different datasets, while Lasso regression might be more sensitive to variations in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d1232",
   "metadata": {},
   "source": [
    "# Degree3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8a495a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Intercept: [-280.94587373]\n",
      "r2_score: -2184.908690358664\n",
      "mse: 182068.26793762363\n",
      "Bias2: 97.79177040377178\n",
      "Variance2: 97.79177040375357\n"
     ]
    }
   ],
   "source": [
    "#degree 3\n",
    "poly=PolynomialFeatures(degree=3, include_bias=True)\n",
    "X_train_poly3=poly.fit_transform(Xtrain_standard)\n",
    "X_test_poly3=poly.fit_transform(Xtest_standard)\n",
    "model=LinearRegression()\n",
    "model.fit(X_train_poly3, Ytrain)\n",
    "Ypred_poly3=model.predict(X_test_poly3)\n",
    "r2_score_poly3=r2_score(Ytest,Ypred_poly3)\n",
    "mse_poly3=mean_squared_error(Ytest, Ypred_poly3)\n",
    "\n",
    "#print(\"Model Coefficients:\", model.coef_)\n",
    "print(\"Model Intercept:\", model.intercept_)\n",
    "print(\"r2_score:\", r2_score_poly3)\n",
    "print(\"mse:\", mse_poly3)\n",
    "\n",
    "\n",
    "y_train_pred3 = model.predict(X_train_poly3)\n",
    "y_test_pred3 = model.predict(X_test_poly3)\n",
    "\n",
    "# Compute bias and variance\n",
    "bias = np.mean((Ytrain - np.mean(y_train_pred3)) ** 2)\n",
    "variance = np.mean(np.var(y_train_pred3))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Bias2:\", bias)\n",
    "print(\"Variance2:\", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe434b8a",
   "metadata": {},
   "source": [
    "# the model's performance is poor, and it is unable to explain any of the variance in the target variable. Overall, these results suggest that the model may suffer from overfitting or underfitting and requires further investigation and possibly revision to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbb44da",
   "metadata": {},
   "source": [
    "# Implement Ridge for improving Bias and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "88df9ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Intercept: [21.06637908]\n",
      "R^2 Score (Ridge): 0.5139706317325587\n",
      "Mean Squared Error (Ridge): 40.482260598337675\n",
      "Bias (Ridge): 98.08438335896695\n",
      "Variance (Ridge): 107.5816109538986\n"
     ]
    }
   ],
   "source": [
    "# Degree 3 polynomial features\n",
    "poly = PolynomialFeatures(degree=3, include_bias=True)\n",
    "X_train_poly3 = poly.fit_transform(Xtrain_standard)\n",
    "X_test_poly3 = poly.transform(Xtest_standard)\n",
    "\n",
    "# Initialize Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)  # You can adjust the alpha parameter as needed\n",
    "\n",
    "# Fit the Ridge regression model\n",
    "ridge_model.fit(X_train_poly3, Ytrain)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred_ridge = ridge_model.predict(X_test_poly3)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2_score_poly3 = r2_score(Ytest, Y_pred_ridge)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_poly3 = mean_squared_error(Ytest, Y_pred_ridge)\n",
    "\n",
    "#print(\"Ridge Coefficients:\", ridge_model.coef_)\n",
    "print(\"Ridge Intercept:\", ridge_model.intercept_)\n",
    "print(\"R^2 Score (Ridge):\", r2_score_poly3)\n",
    "print(\"Mean Squared Error (Ridge):\", mse_poly3)\n",
    "\n",
    "# Use cross-validation to calculate R^2 scores\n",
    "r2_scores_ridge = cross_val_score(ridge_model, X_train_poly3, Ytrain, cv=5)\n",
    "\n",
    "# Calculate bias and variance\n",
    "bias_ridge = np.mean((Ytrain - np.mean(Y_pred_ridge)) ** 2)\n",
    "variance_ridge = np.mean(np.var(Y_pred_ridge))\n",
    "\n",
    "print(\"Bias (Ridge):\", bias_ridge)\n",
    "print(\"Variance (Ridge):\", variance_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556c4ea",
   "metadata": {},
   "source": [
    "# the results suggest that the Ridge regression model significantly improves upon the performance of the polynomial regression model and provides more reliable predictions. The regularization introduced by Ridge regression helps to mitigate overfitting and improve the model's generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb8cea8",
   "metadata": {},
   "source": [
    "# Degree4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "deb20d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients: [[-9.40886258e-13  2.15572280e+00 -3.71735225e+00 ... -5.69394034e-01\n",
      "   7.17360152e-01  6.12890449e-01]]\n",
      "Model Intercept: [17.8370377]\n",
      "r2_score: -49.339806510390645\n",
      "mse: 4192.893060943957\n",
      "Bias2: 97.79177040377179\n",
      "Variance2: 97.79177040377286\n"
     ]
    }
   ],
   "source": [
    "#degree 4\n",
    "poly=PolynomialFeatures(degree=4, include_bias=True)\n",
    "X_train_poly4=poly.fit_transform(Xtrain_standard)\n",
    "X_test_poly4=poly.fit_transform(Xtest_standard)\n",
    "model=LinearRegression()\n",
    "model.fit(X_train_poly4, Ytrain)\n",
    "Ypred_poly4=model.predict(X_test_poly4)\n",
    "r2_score_poly4=r2_score(Ytest,Ypred_poly4)\n",
    "mse_poly4=mean_squared_error(Ytest, Ypred_poly4)\n",
    "\n",
    "print(\"Model Coefficients:\", model.coef_)\n",
    "print(\"Model Intercept:\", model.intercept_)\n",
    "print(\"r2_score:\", r2_score_poly4)\n",
    "print(\"mse:\", mse_poly4)\n",
    "\n",
    "y_train_pred4 = model.predict(X_train_poly4)\n",
    "y_test_pred4 = model.predict(X_test_poly4)\n",
    "\n",
    "# Compute bias and variance\n",
    "bias = np.mean((Ytrain - np.mean(y_train_pred4)) ** 2)\n",
    "variance = np.mean(np.var(y_train_pred4))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Bias2:\", bias)\n",
    "print(\"Variance2:\", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074177e4",
   "metadata": {},
   "source": [
    "# Implement Ridge for improving Bias and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7ece2f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Intercept: [21.97484156]\n",
      "R^2 Score (Ridge): -1.1439543911946326\n",
      "Mean Squared Error (Ridge): 178.5738188716479\n",
      "Bias (Ridge): 102.57908891654331\n",
      "Variance (Ridge): 218.36325622584457\n"
     ]
    }
   ],
   "source": [
    "# Degree 4 polynomial features\n",
    "poly = PolynomialFeatures(degree=4, include_bias=True)\n",
    "X_train_poly4 = poly.fit_transform(Xtrain_standard)\n",
    "X_test_poly4 = poly.transform(Xtest_standard)\n",
    "\n",
    "# Initialize Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)  # You can adjust the alpha parameter as needed\n",
    "\n",
    "# Fit the Ridge regression model\n",
    "ridge_model.fit(X_train_poly4, Ytrain)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred_ridge4 = ridge_model.predict(X_test_poly4)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2_score_poly4 = r2_score(Ytest, Y_pred_ridge4)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_poly4 = mean_squared_error(Ytest, Y_pred_ridge4)       #the differences between observed and predicted values of data.\n",
    "\n",
    "#print(\"Ridge Coefficients:\", ridge_model.coef_)\n",
    "print(\"Ridge Intercept:\", ridge_model.intercept_)\n",
    "print(\"R^2 Score (Ridge):\", r2_score_poly4)\n",
    "print(\"Mean Squared Error (Ridge):\", mse_poly4)\n",
    "\n",
    "# Use cross-validation to calculate R^2 scores\n",
    "r2_scores_ridge = cross_val_score(ridge_model, X_train_poly4, Ytrain, cv=5)\n",
    "\n",
    "# Calculate bias and variance\n",
    "bias_ridge = np.mean((Ytrain - np.mean(Y_pred_ridge4)) ** 2)\n",
    "variance_ridge = np.mean(np.var(Y_pred_ridge4))\n",
    "\n",
    "print(\"Bias (Ridge):\", bias_ridge)\n",
    "print(\"Variance (Ridge):\", variance_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b1394",
   "metadata": {},
   "source": [
    "# In summary, the stability analysis suggests that the polynomial regression model with degree 4 exhibits the highest stability in terms of the inferred beta coefficients, followed by the cubic model (degree 3). The quadratic model (degree 2) shows the lowest stability among the three models. However, it's essential to consider other factors such as model performance and complexity when selecting the optimal polynomial degree for the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c14f9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stability Scores:\n",
      "Polynomial Degree 2: 554477865463.8993\n",
      "Polynomial Degree 3: 4.165486142921723\n",
      "Polynomial Degree 4: 0.3604346761734805\n",
      "beta_coefficients_std:\n",
      "Polynomial Degree 4: [0.0044975  0.6014559  0.6990331  ... 0.13289362 0.20522653 0.2258537 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "#Define polynomial degrees\n",
    "polynomial_degrees = [2, 3, 4]\n",
    "\n",
    "# Create a list to store the stability of each model\n",
    "stability_scores = []\n",
    "\n",
    "for degree in polynomial_degrees:\n",
    "    # Create polynomial features\n",
    "    polynomial_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly_train = polynomial_features.fit_transform(Xtrain_standard)\n",
    "    \n",
    "    # Perform bootstrap resampling and fit the model on each sample\n",
    "    beta_coefficients = []\n",
    "    n_bootstrap = 100  # Number of bootstrap samples\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_sample, y_sample = resample(X_poly_train, Ytrain)\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_sample, y_sample)\n",
    "        beta_coefficients.append(model.coef_)\n",
    "    \n",
    "    # Calculate the standard deviation of beta coefficients across bootstrap samples\n",
    "    beta_coefficients_std = np.std(beta_coefficients, axis=0)\n",
    "    \n",
    "    # Calculate stability score (average standard deviation of beta coefficients)\n",
    "    stability_score = np.mean(beta_coefficients_std)\n",
    "    \n",
    "    # Store the stability score for this model\n",
    "    stability_scores.append((degree, stability_score))\n",
    "\n",
    "# Print stability scores for each model\n",
    "print(\"Stability Scores:\")\n",
    "for degree, stability_score in stability_scores:\n",
    "    print(f\"Polynomial Degree {degree}: {stability_score}\")\n",
    "    \n",
    "print(\"beta_coefficients_std:\")\n",
    "for beta_coefficients_std in beta_coefficients_std:\n",
    "    print(f\"Polynomial Degree {degree}: {beta_coefficients_std}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1d383",
   "metadata": {},
   "source": [
    "# In summary, both models perform poorly on this dataset, and the Ridge regression model does not provide significant improvement over the polynomial regression model. It's possible that neither model is suitable for accurately predicting the target variable in this case. Further analysis and potentially different modeling approaches may be necessary to improve predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf8677",
   "metadata": {},
   "source": [
    "# Consider polynomial 2,3 and 4 with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4239283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Degree: 2\n",
      "R-squared (Train): 0.9305, R-squared (Test): -0.7925\n",
      "MSE (Train): 6.7963, MSE (Test): 149.2986\n",
      "Bias: 90.9955\n",
      "Variance: 90.9955\n",
      "\n",
      "Polynomial Degree: 3\n",
      "R-squared (Train): 1.0000, R-squared (Test): -2184.9087\n",
      "MSE (Train): 0.0000, MSE (Test): 182068.2679\n",
      "Bias: 97.7918\n",
      "Variance: 97.7918\n",
      "\n",
      "Polynomial Degree: 4\n",
      "R-squared (Train): 1.0000, R-squared (Test): -49.3398\n",
      "MSE (Train): 0.0000, MSE (Test): 4192.8931\n",
      "Bias: 97.7918\n",
      "Variance: 97.7918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define polynomial degrees\n",
    "degrees = [2, 3, 4]\n",
    "\n",
    "for degree in degrees:\n",
    "    # Generate polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(Xtrain_standard)\n",
    "    X_test_poly = poly.transform(Xtest_standard)\n",
    "    \n",
    "    # Initialize and fit the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, Ytrain)\n",
    "    \n",
    "    # Make predictions\n",
    "    Y_pred_train = model.predict(X_train_poly)\n",
    "    Y_pred_test = model.predict(X_test_poly)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    r2_train = r2_score(Ytrain, Y_pred_train)\n",
    "    r2_test = r2_score(Ytest, Y_pred_test)\n",
    "    \n",
    "    # Calculate Mean Squared Error\n",
    "    mse_train = mean_squared_error(Ytrain, Y_pred_train)\n",
    "    mse_test = mean_squared_error(Ytest, Y_pred_test)\n",
    "    \n",
    "    # Calculate bias\n",
    "    bias = np.mean((Y_pred_train - np.mean(Y_pred_train)) ** 2)\n",
    "    \n",
    "    # Calculate variance\n",
    "    variance = np.mean(np.var(Y_pred_train))\n",
    "    \n",
    "    print(f\"Polynomial Degree: {degree}\")\n",
    "    print(f\"R-squared (Train): {r2_train:.4f}, R-squared (Test): {r2_test:.4f}\")\n",
    "    print(f\"MSE (Train): {mse_train:.4f}, MSE (Test): {mse_test:.4f}\")\n",
    "    print(f\"Bias: {bias:.4f}\")\n",
    "    print(f\"Variance: {variance:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf12899",
   "metadata": {},
   "source": [
    "# R-squared value on the testing set is negative, indicating poor generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076039d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4acbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5124c15e",
   "metadata": {},
   "source": [
    "# load a new dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a26426fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Age</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Tax</th>\n",
       "      <th>DisadvantagedPosition</th>\n",
       "      <th>Crime</th>\n",
       "      <th>NitricOxides</th>\n",
       "      <th>PupilTeacher</th>\n",
       "      <th>Residential</th>\n",
       "      <th>NonRetail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.438</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.3967</td>\n",
       "      <td>7</td>\n",
       "      <td>330</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.21409</td>\n",
       "      <td>0.431</td>\n",
       "      <td>19.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.875</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.6484</td>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.01381</td>\n",
       "      <td>0.422</td>\n",
       "      <td>14.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.404</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.6390</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.31</td>\n",
       "      <td>9.59571</td>\n",
       "      <td>0.693</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.417</td>\n",
       "      <td>66.1</td>\n",
       "      <td>3.0923</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>8.81</td>\n",
       "      <td>0.04684</td>\n",
       "      <td>0.489</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.290</td>\n",
       "      <td>17.8</td>\n",
       "      <td>6.6115</td>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.03584</td>\n",
       "      <td>0.398</td>\n",
       "      <td>16.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.163</td>\n",
       "      <td>79.9</td>\n",
       "      <td>3.2157</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.41238</td>\n",
       "      <td>0.504</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.594</td>\n",
       "      <td>36.8</td>\n",
       "      <td>6.4980</td>\n",
       "      <td>4</td>\n",
       "      <td>345</td>\n",
       "      <td>13.09</td>\n",
       "      <td>0.13554</td>\n",
       "      <td>0.409</td>\n",
       "      <td>18.9</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.875</td>\n",
       "      <td>94.6</td>\n",
       "      <td>2.4259</td>\n",
       "      <td>5</td>\n",
       "      <td>403</td>\n",
       "      <td>14.43</td>\n",
       "      <td>1.20742</td>\n",
       "      <td>0.605</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.426</td>\n",
       "      <td>52.3</td>\n",
       "      <td>4.5404</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.16760</td>\n",
       "      <td>0.493</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.009</td>\n",
       "      <td>42.3</td>\n",
       "      <td>5.5027</td>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.08199</td>\n",
       "      <td>0.437</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms    Age  Distance  Accessibility  Tax  DisadvantagedPosition    Crime  \\\n",
       "0  6.438    8.9    7.3967              7  330                   3.59  0.21409   \n",
       "1  7.875   32.0    5.6484              4  255                   2.97  0.01381   \n",
       "2  6.404  100.0    1.6390             24  666                  20.31  9.59571   \n",
       "3  6.417   66.1    3.0923              2  270                   8.81  0.04684   \n",
       "4  6.290   17.8    6.6115              4  337                   4.67  0.03584   \n",
       "5  7.163   79.9    3.2157              8  307                   6.36  0.41238   \n",
       "6  5.594   36.8    6.4980              4  345                  13.09  0.13554   \n",
       "7  5.875   94.6    2.4259              5  403                  14.43  1.20742   \n",
       "8  6.426   52.3    4.5404              5  287                   7.20  0.16760   \n",
       "9  6.009   42.3    5.5027              4  289                  10.40  0.08199   \n",
       "\n",
       "   NitricOxides  PupilTeacher  Residential  NonRetail  \n",
       "0         0.431          19.1         22.0       5.86  \n",
       "1         0.422          14.4         80.0       0.46  \n",
       "2         0.693          20.2          0.0      18.10  \n",
       "3         0.489          17.8          0.0       3.41  \n",
       "4         0.398          16.1         80.0       3.37  \n",
       "5         0.504          17.4          0.0       6.20  \n",
       "6         0.409          18.9         12.5       6.07  \n",
       "7         0.605          14.7          0.0      19.58  \n",
       "8         0.493          19.6          0.0       7.38  \n",
       "9         0.437          16.0          0.0      13.92  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew=pd.read_csv(r\"C:\\Users\\Kyle\\Desktop\\Middlesex uni\\Machine Learning\\Week8\\house_unseen.csv\")\n",
    "dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "72a40e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Rooms                  10 non-null     float64\n",
      " 1   Age                    10 non-null     float64\n",
      " 2   Distance               10 non-null     float64\n",
      " 3   Accessibility          10 non-null     int64  \n",
      " 4   Tax                    10 non-null     int64  \n",
      " 5   DisadvantagedPosition  10 non-null     float64\n",
      " 6   Crime                  10 non-null     float64\n",
      " 7   NitricOxides           10 non-null     float64\n",
      " 8   PupilTeacher           10 non-null     float64\n",
      " 9   Residential            10 non-null     float64\n",
      " 10  NonRetail              10 non-null     float64\n",
      "dtypes: float64(9), int64(2)\n",
      "memory usage: 1012.0 bytes\n"
     ]
    }
   ],
   "source": [
    "dfnew.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "944b6fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Age</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Tax</th>\n",
       "      <th>DisadvantagedPosition</th>\n",
       "      <th>Crime</th>\n",
       "      <th>NitricOxides</th>\n",
       "      <th>PupilTeacher</th>\n",
       "      <th>Residential</th>\n",
       "      <th>NonRetail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.438</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.3967</td>\n",
       "      <td>7</td>\n",
       "      <td>330</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.21409</td>\n",
       "      <td>0.431</td>\n",
       "      <td>19.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.875</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.6484</td>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.01381</td>\n",
       "      <td>0.422</td>\n",
       "      <td>14.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.404</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.6390</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.31</td>\n",
       "      <td>9.59571</td>\n",
       "      <td>0.693</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.417</td>\n",
       "      <td>66.1</td>\n",
       "      <td>3.0923</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>8.81</td>\n",
       "      <td>0.04684</td>\n",
       "      <td>0.489</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.290</td>\n",
       "      <td>17.8</td>\n",
       "      <td>6.6115</td>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.03584</td>\n",
       "      <td>0.398</td>\n",
       "      <td>16.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.163</td>\n",
       "      <td>79.9</td>\n",
       "      <td>3.2157</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.41238</td>\n",
       "      <td>0.504</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.594</td>\n",
       "      <td>36.8</td>\n",
       "      <td>6.4980</td>\n",
       "      <td>4</td>\n",
       "      <td>345</td>\n",
       "      <td>13.09</td>\n",
       "      <td>0.13554</td>\n",
       "      <td>0.409</td>\n",
       "      <td>18.9</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.875</td>\n",
       "      <td>94.6</td>\n",
       "      <td>2.4259</td>\n",
       "      <td>5</td>\n",
       "      <td>403</td>\n",
       "      <td>14.43</td>\n",
       "      <td>1.20742</td>\n",
       "      <td>0.605</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.426</td>\n",
       "      <td>52.3</td>\n",
       "      <td>4.5404</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.16760</td>\n",
       "      <td>0.493</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.009</td>\n",
       "      <td>42.3</td>\n",
       "      <td>5.5027</td>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.08199</td>\n",
       "      <td>0.437</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms    Age  Distance  Accessibility  Tax  DisadvantagedPosition    Crime  \\\n",
       "0  6.438    8.9    7.3967              7  330                   3.59  0.21409   \n",
       "1  7.875   32.0    5.6484              4  255                   2.97  0.01381   \n",
       "2  6.404  100.0    1.6390             24  666                  20.31  9.59571   \n",
       "3  6.417   66.1    3.0923              2  270                   8.81  0.04684   \n",
       "4  6.290   17.8    6.6115              4  337                   4.67  0.03584   \n",
       "5  7.163   79.9    3.2157              8  307                   6.36  0.41238   \n",
       "6  5.594   36.8    6.4980              4  345                  13.09  0.13554   \n",
       "7  5.875   94.6    2.4259              5  403                  14.43  1.20742   \n",
       "8  6.426   52.3    4.5404              5  287                   7.20  0.16760   \n",
       "9  6.009   42.3    5.5027              4  289                  10.40  0.08199   \n",
       "\n",
       "   NitricOxides  PupilTeacher  Residential  NonRetail  \n",
       "0         0.431          19.1         22.0       5.86  \n",
       "1         0.422          14.4         80.0       0.46  \n",
       "2         0.693          20.2          0.0      18.10  \n",
       "3         0.489          17.8          0.0       3.41  \n",
       "4         0.398          16.1         80.0       3.37  \n",
       "5         0.504          17.4          0.0       6.20  \n",
       "6         0.409          18.9         12.5       6.07  \n",
       "7         0.605          14.7          0.0      19.58  \n",
       "8         0.493          19.6          0.0       7.38  \n",
       "9         0.437          16.0          0.0      13.92  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_=dfnew\n",
    "X_new_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b66fbc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_standard=scaler.fit(X_new_)\n",
    "X_new_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2e292816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01794446, -1.48584993,  1.46358924,  0.05013247, -0.16691652,\n",
       "        -1.07562106, -0.34625514, -0.63624221,  0.86277594,  0.08205669,\n",
       "        -0.41742036],\n",
       "       [ 2.30513603, -0.70878103,  0.52960044, -0.45119222, -0.82928368,\n",
       "        -1.19485672, -0.41723334, -0.73652557, -1.55094246,  1.9484442 ,\n",
       "        -1.29278732],\n",
       "       [-0.07290949,  1.57869452, -1.61232867,  2.89097238,  2.80048833,\n",
       "         2.1398955 ,  2.97854294,  2.28311784,  1.42768875, -0.6258834 ,\n",
       "         1.56674475],\n",
       "       [-0.05189345,  0.43832068, -0.8359368 , -0.78540868, -0.69681025,\n",
       "        -0.07173371, -0.40552768,  0.01002834,  0.1951517 , -0.6258834 ,\n",
       "        -0.81457759],\n",
       "       [-0.25720397, -1.18645974,  1.04411432, -0.45119222, -0.10509559,\n",
       "        -0.86792023, -0.40942602, -1.00394786, -0.67789538,  1.9484442 ,\n",
       "        -0.82106179],\n",
       "       [ 1.1541038 ,  0.90254366, -0.77001321,  0.2172407 , -0.37004245,\n",
       "        -0.54290689, -0.27598218,  0.17716727, -0.01027114, -0.6258834 ,\n",
       "        -0.36230466],\n",
       "       [-1.3823703 , -0.54731216,  0.98347957, -0.45119222, -0.03444309,\n",
       "         0.75137698, -0.37409285, -0.88137931,  0.76006452, -0.22364471,\n",
       "        -0.38337831],\n",
       "       [-0.92810056,  1.39704205, -1.19194557, -0.28408399,  0.47778751,\n",
       "         1.00907987,  0.00577593,  1.30256943, -1.39687533, -0.6258834 ,\n",
       "         1.80666014],\n",
       "       [-0.03734388, -0.0259023 , -0.0623229 , -0.28408399, -0.54667369,\n",
       "        -0.3813618 , -0.36273095,  0.05459872,  1.11955449, -0.6258834 ,\n",
       "        -0.17102077],\n",
       "       [-0.71147371, -0.36229576,  0.45176359, -0.45119222, -0.52901057,\n",
       "         0.23404807, -0.3930707 , -0.56938663, -0.72925109, -0.6258834 ,\n",
       "         0.88914588]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "X_new_standard=scaler.fit_transform(X_new_)\n",
    "X_new_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "757b3e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "540c564b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.849686830663793\n",
      "Mean Squared Error: 12.51985433333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([26.063, 45.959,  7.585, 20.025, 22.97 , 31.916, 18.353, 14.887,\n",
       "       22.84 , 20.584])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Random Forest Regressor with default parameters\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_regressor.fit(Xtrain_standard, Ytrain)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rf_regressor.predict(Xtest_standard)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(Ytest, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(Ytest, y_pred)\n",
    "\n",
    "print(\"R^2 Score:\", r2)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "y_predunseen = rf_regressor.predict(X_new_standard)\n",
    "\n",
    "y_predunseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2b8b7cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Price\n",
       "0           26.063\n",
       "1           45.959\n",
       "2            7.585\n",
       "3           20.025\n",
       "4           22.970\n",
       "5           31.916\n",
       "6           18.353\n",
       "7           14.887\n",
       "8           22.840\n",
       "9           20.584"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predunseen_df = pd.DataFrame({'Predicted_Price': y_predunseen})\n",
    "y_predunseen_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cde023",
   "metadata": {},
   "source": [
    "# Generate price predictions for the houses within the dataset located in the\n",
    "house_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "15f38cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Age</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Tax</th>\n",
       "      <th>DisadvantagedPosition</th>\n",
       "      <th>Crime</th>\n",
       "      <th>NitricOxides</th>\n",
       "      <th>PupilTeacher</th>\n",
       "      <th>Residential</th>\n",
       "      <th>NonRetail</th>\n",
       "      <th>Predicted_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.438</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.3967</td>\n",
       "      <td>7</td>\n",
       "      <td>330</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.21409</td>\n",
       "      <td>0.431</td>\n",
       "      <td>19.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.86</td>\n",
       "      <td>26.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.875</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.6484</td>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.01381</td>\n",
       "      <td>0.422</td>\n",
       "      <td>14.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>45.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.404</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.6390</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.31</td>\n",
       "      <td>9.59571</td>\n",
       "      <td>0.693</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>7.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.417</td>\n",
       "      <td>66.1</td>\n",
       "      <td>3.0923</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>8.81</td>\n",
       "      <td>0.04684</td>\n",
       "      <td>0.489</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.41</td>\n",
       "      <td>20.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.290</td>\n",
       "      <td>17.8</td>\n",
       "      <td>6.6115</td>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.03584</td>\n",
       "      <td>0.398</td>\n",
       "      <td>16.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>22.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.163</td>\n",
       "      <td>79.9</td>\n",
       "      <td>3.2157</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.41238</td>\n",
       "      <td>0.504</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>31.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.594</td>\n",
       "      <td>36.8</td>\n",
       "      <td>6.4980</td>\n",
       "      <td>4</td>\n",
       "      <td>345</td>\n",
       "      <td>13.09</td>\n",
       "      <td>0.13554</td>\n",
       "      <td>0.409</td>\n",
       "      <td>18.9</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.07</td>\n",
       "      <td>18.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.875</td>\n",
       "      <td>94.6</td>\n",
       "      <td>2.4259</td>\n",
       "      <td>5</td>\n",
       "      <td>403</td>\n",
       "      <td>14.43</td>\n",
       "      <td>1.20742</td>\n",
       "      <td>0.605</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>14.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.426</td>\n",
       "      <td>52.3</td>\n",
       "      <td>4.5404</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.16760</td>\n",
       "      <td>0.493</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>22.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.009</td>\n",
       "      <td>42.3</td>\n",
       "      <td>5.5027</td>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.08199</td>\n",
       "      <td>0.437</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.92</td>\n",
       "      <td>20.584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms    Age  Distance  Accessibility  Tax  DisadvantagedPosition    Crime  \\\n",
       "0  6.438    8.9    7.3967              7  330                   3.59  0.21409   \n",
       "1  7.875   32.0    5.6484              4  255                   2.97  0.01381   \n",
       "2  6.404  100.0    1.6390             24  666                  20.31  9.59571   \n",
       "3  6.417   66.1    3.0923              2  270                   8.81  0.04684   \n",
       "4  6.290   17.8    6.6115              4  337                   4.67  0.03584   \n",
       "5  7.163   79.9    3.2157              8  307                   6.36  0.41238   \n",
       "6  5.594   36.8    6.4980              4  345                  13.09  0.13554   \n",
       "7  5.875   94.6    2.4259              5  403                  14.43  1.20742   \n",
       "8  6.426   52.3    4.5404              5  287                   7.20  0.16760   \n",
       "9  6.009   42.3    5.5027              4  289                  10.40  0.08199   \n",
       "\n",
       "   NitricOxides  PupilTeacher  Residential  NonRetail  Predicted_Price  \n",
       "0         0.431          19.1         22.0       5.86           26.063  \n",
       "1         0.422          14.4         80.0       0.46           45.959  \n",
       "2         0.693          20.2          0.0      18.10            7.585  \n",
       "3         0.489          17.8          0.0       3.41           20.025  \n",
       "4         0.398          16.1         80.0       3.37           22.970  \n",
       "5         0.504          17.4          0.0       6.20           31.916  \n",
       "6         0.409          18.9         12.5       6.07           18.353  \n",
       "7         0.605          14.7          0.0      19.58           14.887  \n",
       "8         0.493          19.6          0.0       7.38           22.840  \n",
       "9         0.437          16.0          0.0      13.92           20.584  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([dfnew, y_predunseen_df], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
